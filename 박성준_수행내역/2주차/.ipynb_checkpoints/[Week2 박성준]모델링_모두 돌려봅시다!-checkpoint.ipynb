{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2주차 과제 제출에 포함되어야 하는 형태 (최소)\n",
    "1. 모델링에 대한 결과 .ipynb 파일 (team1_onboarding_week2_analysis.ipynb)\n",
    "2. np.random.seed(42) 설정\n",
    "3. Input : X데이터 : [user_id, +@]\n",
    "4. Output : Count column 예측값\n",
    "5. 2020.01.01~2020.09.30 : Training Data\n",
    "6. 2020.10.01~2020.12.31 : Test Data\n",
    "7. 2020.10.01~2020.12.31 구간에 대한 MSE, MAE 계산값\n",
    "8. 요일별 이용량에 대한 분석 - EDA\n",
    "9. 유저별 이용 count 값에 대한 분석 - EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # (Windows 용) 한글 출력을 위한 글꼴 설정\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 랜덤시드 통일\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_font_family():\n",
    "    \"\"\"\n",
    "    시스템 환경에 따른 기본 폰트명을 반환하는 함수\n",
    "    \"\"\"\n",
    "    import platform\n",
    "    system_name = platform.system()\n",
    "    # colab 사용자는 system_name이 'Linux'로 확인\n",
    "\n",
    "    if system_name == \"Darwin\" :\n",
    "        font_family = \"AppleGothic\"\n",
    "    elif system_name == \"Windows\":\n",
    "        font_family = \"Malgun Gothic\"\n",
    "    else:\n",
    "        # Linux\n",
    "        # colab에서는 runtime을 <꼭> 재시작 해야함.\n",
    "        # 런타임을 재시작 하지 않고 폰트 설치를 하면 기본 설정 폰트가 로드되어 한글이 깨짐.\n",
    "        !apt-get update -qq\n",
    "        !apt-get install fonts-nanum -qq  > /dev/null\n",
    "\n",
    "        import matplotlib.font_manager as fm\n",
    "\n",
    "        fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "        font = fm.FontProperties(fname=fontpath, size=9)\n",
    "        fm._rebuild()\n",
    "        font_family = \"NanumBarunGothic\"\n",
    "    return font_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화를 위한 폰트설정\n",
    "# 위에서 만든 함수를 통해 시스템 폰트를 불러와서 font_family 라는 변수에 할당.\n",
    "a = get_font_family()\n",
    "# 폰트설정\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", family = a)\n",
    "# 마이너스폰트 설정\n",
    "plt.rc(\"axes\", unicode_minus=False)\n",
    "# ggplot으로 그래프 스타일 설정 / 개인 자유\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020교통량통합.xlsx',\n",
       " 'check.csv',\n",
       " 'final.csv',\n",
       " 'holiday.csv',\n",
       " 'metro.csv',\n",
       " '교통량정리.csv',\n",
       " '국가공휴일.xlsx',\n",
       " '기상청.csv',\n",
       " '디지털 스킬셋 기술과제.docx',\n",
       " '서울시_기상데이터.csv',\n",
       " '실전db.csv',\n",
       " '실전db_holiday.csv',\n",
       " '지하철노선위경도정보3.xlsx',\n",
       " '최종.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 불러오기\n",
    "df = pd.read_csv(\"./data/최종.csv\")\n",
    "df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "df = df.sort_values(by=\"DATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[:623305]\n",
    "X_test = df[623305:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train['COUNT']\n",
    "X_train = X_train.drop([\"DATE\", \"COUNT\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_count = X_test['COUNT']\n",
    "X_test = X_test.drop([\"DATE\", \"COUNT\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_split :  (498644, 19)\n",
      "X_val_split :  (124661, 19)\n",
      "y_train_split :  (498644,)\n",
      "y_val_split :  (124661,)\n"
     ]
    }
   ],
   "source": [
    "# 유효성 검사 데이터 셋 \n",
    "\n",
    "random_state = 42\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train,\n",
    "                                                                         random_state=random_state,\n",
    "                                                                         test_size=0.2)\n",
    "\n",
    "\n",
    "print(\"X_train_split : \", X_train_split.shape)\n",
    "print(\"X_val_split : \", X_val_split.shape)\n",
    "print(\"y_train_split : \", y_train_split.shape)\n",
    "print(\"y_val_split : \", y_val_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnt_predict(model, X_train, y_train, kind=\"default\", print_len=7):\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train,\n",
    "                                                                         random_state=random_state,\n",
    "                                                                         test_size=0.2)\n",
    "    model.fit(X_train_split, y_train_split)\n",
    "    y_pred_train = model.predict(X_train_split)\n",
    "    model_name = model.__class__.__name__\n",
    "    print(\"#### \" +model_name+\" month prediction(\"+kind+\") ####\")\n",
    "    print(\"y_train[:{}] : {}\".format(print_len, np.round(y_train_split[:print_len].values,1)))\n",
    "    print(\"y_pred_train[:{}] : {}\".format(print_len, np.round(y_pred_train[:print_len],1)))\n",
    "    print()\n",
    "    y_pred_val = model.predict(X_val_split)\n",
    "    print(\"y_val[:{}] : {}\".format(print_len, np.round(y_val_split[:print_len].values,1)))\n",
    "    print(\"y_pred_val[:{}] : {}\".format(print_len, np.round(y_pred_val[:print_len],1)))\n",
    "    rmse = np.sqrt(mean_squared_error(y_pred_val, y_val_split))\n",
    "    print(\"rmse : {:.6f}\".format(rmse))\n",
    "    print(\"----------\\n\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "def average_model_evaluation(models, X_train, y_train, kind=\"default\", print_len=7):\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train.values, y_train.values,\n",
    "                                                                         random_state=random_state,\n",
    "                                                                         test_size=0.2)\n",
    "    pred_vals = []\n",
    "    print(\"####### average model #######\\n\\n\")\n",
    "    for model in models:\n",
    "        model.fit(X_train_split, y_train_split)\n",
    "        y_pred_train = model.predict(X_train_split)\n",
    "        model_name = model.__class__.__name__\n",
    "        print(\"#### \" +model_name+\"  prediction(\"+kind+\") ####\")\n",
    "        print(\"y_train[:{}] : {}\".format(print_len, np.round(y_train_split[:print_len],1)))\n",
    "        print(\"y_pred_train[:{}] : {}\".format(print_len, np.round(y_pred_train[:print_len],1)))\n",
    "        print()\n",
    "        y_pred_val = model.predict(X_val_split)\n",
    "        pred_vals.append(y_pred_val)\n",
    "        print(\"y_val[:{}] : {}\".format(print_len, np.round(y_val_split[:print_len],1)))\n",
    "        print(\"y_pred_val[:{}] : {}\".format(print_len, np.round(y_pred_val[:print_len],1)))\n",
    "        rmse = np.sqrt(mean_squared_error(y_pred_val, y_val_split))\n",
    "        print(\"rmse : {:.6f}\".format(rmse))\n",
    "        print(\"----------\\n\")\n",
    "    print(\"seperated model evaluation ended\\n\")\n",
    "    print(\"### average model evaluation ###\")\n",
    "    y_pred = np.mean(pred_vals, axis=0)\n",
    "    print(\"average model validation predictions : \", y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_pred, y_val_split))\n",
    "    print(\"average model rmse : {:.6f}\".format(rmse))\n",
    "    print(\"-------------------------------\")\n",
    "    return models, pred_vals\n",
    "\n",
    "# 모델 예측 평균\n",
    "def average_model_prediction(models, X_test, kind=\"default\", print_len=20):\n",
    "    print()\n",
    "    pred_tests = []\n",
    "    print(\"####### average model #######\\n\\n\")\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        print(\"#### \" +model_name+\" prediction(\"+kind+\") ####\")\n",
    "        print(X_test.shape)\n",
    "        y_pred_test = model.predict(X_test.values)\n",
    "        print(\"y_pred_test[:{}] : {}\".format(print_len, np.round(y_pred_test[:print_len],1)))\n",
    "        pred_tests.append(y_pred_test)\n",
    "\n",
    "    y_pred = np.mean(pred_tests, axis=0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### average model #######\n",
      "\n",
      "\n",
      "#### RandomForestRegressor  prediction(default) ####\n",
      "y_train[:7] : [1 1 1 1 1 1 1]\n",
      "y_pred_train[:7] : [1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "y_val[:7] : [1 1 1 1 1 1 1]\n",
      "y_pred_val[:7] : [1. 1. 1. 1. 1. 1. 1.]\n",
      "rmse : 0.171817\n",
      "----------\n",
      "\n",
      "#### LGBMRegressor  prediction(default) ####\n",
      "y_train[:7] : [1 1 1 1 1 1 1]\n",
      "y_pred_train[:7] : [1.1 1.  1.  1.1 1.  1.  1. ]\n",
      "\n",
      "y_val[:7] : [1 1 1 1 1 1 1]\n",
      "y_pred_val[:7] : [1.  1.1 1.  1.  1.  1.  1.1]\n",
      "rmse : 0.160891\n",
      "----------\n",
      "\n",
      "#### XGBRegressor  prediction(default) ####\n",
      "y_train[:7] : [1 1 1 1 1 1 1]\n",
      "y_pred_train[:7] : [1.1 1.  1.  1.1 1.  1.  1. ]\n",
      "\n",
      "y_val[:7] : [1 1 1 1 1 1 1]\n",
      "y_pred_val[:7] : [1.  1.1 1.  1.  1.  1.  1.1]\n",
      "rmse : 0.165250\n",
      "----------\n",
      "\n",
      "#### GradientBoostingRegressor  prediction(default) ####\n",
      "y_train[:7] : [1 1 1 1 1 1 1]\n",
      "y_pred_train[:7] : [1.2 1.  1.  1.1 1.  1.  1. ]\n",
      "\n",
      "y_val[:7] : [1 1 1 1 1 1 1]\n",
      "y_pred_val[:7] : [1.  1.1 1.  1.  1.  1.  1.1]\n",
      "rmse : 0.161544\n",
      "----------\n",
      "\n",
      "seperated model evaluation ended\n",
      "\n",
      "### average model evaluation ###\n",
      "average model validation predictions :  [1.00046425 1.06743492 1.00000255 ... 1.00017552 0.99967038 1.53384621]\n",
      "average model rmse : 0.159969\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor(random_state=random_state)\n",
    "lgbm_regressor = LGBMRegressor(random_state=random_state)\n",
    "xgb_regressor = XGBRegressor(random_state=random_state)\n",
    "gb_regressor = GradientBoostingRegressor(random_state=random_state)\n",
    "\n",
    "default_models = [rf_regressor, lgbm_regressor, xgb_regressor, gb_regressor]\n",
    "default_models, pred_vals = average_model_evaluation(default_models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####### average model #######\n",
      "\n",
      "\n",
      "#### RandomForestRegressor prediction(default) ####\n",
      "(255600, 19)\n",
      "y_pred_test[:20] : [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "#### LGBMRegressor prediction(default) ####\n",
      "(255600, 19)\n",
      "y_pred_test[:20] : [1.  1.  1.  1.  1.  1.2 1.  1.  1.  1.  1.  1.  1.  1.1 1.  1.  1.  1.\n",
      " 1.  1. ]\n",
      "#### XGBRegressor prediction(default) ####\n",
      "(255600, 19)\n",
      "y_pred_test[:20] : [1.  1.  1.  1.  1.  1.2 1.  1.  1.  1.  1.  1.  1.  1.1 1.  1.  1.  1.\n",
      " 1.  1. ]\n",
      "#### GradientBoostingRegressor prediction(default) ####\n",
      "(255600, 19)\n",
      "y_pred_test[:20] : [1.  1.  1.  1.  1.  1.1 1.  1.  1.  1.  1.  1.  1.  1.1 1.  1.  1.  1.\n",
      " 1.  1. ]\n",
      "[1.00007483 0.99996857 1.00012543 ... 0.93866545 0.99964852 0.93866545]\n"
     ]
    }
   ],
   "source": [
    "y_pred = average_model_prediction(default_models, X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03948857802555759"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(real_count, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
