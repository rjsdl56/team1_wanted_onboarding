{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2주차 과제 제출에 포함되어야 하는 형태 (최소)\n",
    "1. 모델링에 대한 결과 .ipynb 파일 (team1_onboarding_week2_analysis.ipynb)\n",
    "2. np.random.seed(42) 설정\n",
    "3. Input : X데이터 : [user_id, +@]\n",
    "4. Output : Count column 예측값\n",
    "5. 2020.01.01~2020.09.30 : Training Data\n",
    "6. 2020.10.01~2020.12.31 : Test Data\n",
    "7. 2020.10.01~2020.12.31 구간에 대한 MSE, MAE 계산값\n",
    "8. 요일별 이용량에 대한 분석 - EDA\n",
    "9. 유저별 이용 count 값에 대한 분석 - EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # (Windows 용) 한글 출력을 위한 글꼴 설정\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 랜덤시드 통일\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_font_family():\n",
    "    \"\"\"\n",
    "    시스템 환경에 따른 기본 폰트명을 반환하는 함수\n",
    "    \"\"\"\n",
    "    import platform\n",
    "    system_name = platform.system()\n",
    "    # colab 사용자는 system_name이 'Linux'로 확인\n",
    "\n",
    "    if system_name == \"Darwin\" :\n",
    "        font_family = \"AppleGothic\"\n",
    "    elif system_name == \"Windows\":\n",
    "        font_family = \"Malgun Gothic\"\n",
    "    else:\n",
    "        # Linux\n",
    "        # colab에서는 runtime을 <꼭> 재시작 해야함.\n",
    "        # 런타임을 재시작 하지 않고 폰트 설치를 하면 기본 설정 폰트가 로드되어 한글이 깨짐.\n",
    "        !apt-get update -qq\n",
    "        !apt-get install fonts-nanum -qq  > /dev/null\n",
    "\n",
    "        import matplotlib.font_manager as fm\n",
    "\n",
    "        fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "        font = fm.FontProperties(fname=fontpath, size=9)\n",
    "        fm._rebuild()\n",
    "        font_family = \"NanumBarunGothic\"\n",
    "    return font_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화를 위한 폰트설정\n",
    "# 위에서 만든 함수를 통해 시스템 폰트를 불러와서 font_family 라는 변수에 할당.\n",
    "a = get_font_family()\n",
    "# 폰트설정\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", family = a)\n",
    "# 마이너스폰트 설정\n",
    "plt.rc(\"axes\", unicode_minus=False)\n",
    "# ggplot으로 그래프 스타일 설정 / 개인 자유\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020교통량통합.xlsx',\n",
       " 'check.csv',\n",
       " 'final.csv',\n",
       " 'holiday.csv',\n",
       " 'metro.csv',\n",
       " '교통량정리.csv',\n",
       " '국가공휴일.xlsx',\n",
       " '기상청.csv',\n",
       " '디지털 스킬셋 기술과제.docx',\n",
       " '서울시_기상데이터.csv',\n",
       " '실전db.csv',\n",
       " '실전db_holiday.csv',\n",
       " '지하철노선위경도정보3.xlsx',\n",
       " '최종.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 불러오기\n",
    "df = pd.read_csv(\"./data/최종.csv\")\n",
    "df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "df = df.sort_values(by=\"DATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[:623305]\n",
    "X_test = df[623305:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = X_train.drop([\"DATE\", \"COUNT\"], axis=1)\n",
    "train_y = X_train['COUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = X_test.drop([\"DATE\", \"COUNT\"], axis=1)\n",
    "real_count = X_test['COUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "gboost = GradientBoostingRegressor(random_state=random_state)\n",
    "xgboost = XGBRegressor(random_state=random_state)\n",
    "lightgbm = LGBMRegressor(random_state=random_state)\n",
    "rdforest = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "models = [gboost, xgboost, lightgbm, rdforest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(models, train_x, train_y, test_x):\n",
    "    df = {}\n",
    "\n",
    "    for model in models:      \n",
    "        model.fit(train_x, train_y)\n",
    "        y_pred = model.predict(test_x)\n",
    "        print(\"사용한 모델 :\",model)\n",
    "        print(\"MSE :\",mean_squared_error(real_count, y_pred))\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용한 모델 : GradientBoostingRegressor(random_state=42)\n",
      "MSE : 0.03795805688767001\n",
      "\n",
      "\n",
      "사용한 모델 : XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "MSE : 0.03869691377648899\n",
      "\n",
      "\n",
      "사용한 모델 : LGBMRegressor(random_state=42)\n",
      "MSE : 0.03599285384130974\n",
      "\n",
      "\n",
      "사용한 모델 : RandomForestRegressor(random_state=42)\n",
      "MSE : 0.046690254564686534\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_scores(models, train_x, train_y, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm이 가장 낮다!!\n",
    "# 해당 모델의 가장 좋은 파라미터를 찾아보자\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 파라미터 범위\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 30, 50],\n",
    "    'max_depth': [10, 20],\n",
    "    'learning_rate' : [0.05],\n",
    "    'num_iterations' : [100,200],\n",
    "}\n",
    "\n",
    "# 모델 준비 (LGBMRegressor)\n",
    "model = LGBMRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=5)]: Done  60 out of  60 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param : {'learning_rate': 0.05, 'max_depth': 20, 'n_estimators': 10, 'num_iterations': 200}\n"
     ]
    }
   ],
   "source": [
    "# 위 과정을 함수로 만들어 여러 모델에 시험해봅시다.\n",
    "\n",
    "GCV = GridSearchCV(model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=5)\n",
    "\n",
    "\n",
    "# 모델 fitting\n",
    "GCV.fit(train_x, train_y)\n",
    "\n",
    "# 가장 좋은 파라미터 찾기\n",
    "print(\"Best Param :\", GCV.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 파라미터로 모델 설정\n",
    "model=GCV.best_estimator_ \n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.03596898702809573\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE :\",mean_squared_error(real_count, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydatavenv",
   "language": "python",
   "name": "pydatavenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
